{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67637e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T18:27:26.702563Z",
     "iopub.status.busy": "2025-08-08T18:27:26.702297Z",
     "iopub.status.idle": "2025-08-08T18:30:49.135570Z",
     "shell.execute_reply": "2025-08-08T18:30:49.134822Z"
    },
    "papermill": {
     "duration": 202.437866,
     "end_time": "2025-08-08T18:30:49.137022",
     "exception": false,
     "start_time": "2025-08-08T18:27:26.699156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7efc91b94090>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/huggingface-hub/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7efc91b94e90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/huggingface-hub/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7efc91b96250>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/huggingface-hub/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7efc91b97190>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/huggingface-hub/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7efc91b943d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/huggingface-hub/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement huggingface-hub<1.0,>=0.34.0 (from transformers) (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for huggingface-hub<1.0,>=0.34.0\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# INSTALL OFFLINE PACKAGES\n",
    "!pip install /kaggle/input/jigsaw-package/pip_packages/transformers-4.55.0-py3-none-any.whl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c4f7f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T18:30:49.142524Z",
     "iopub.status.busy": "2025-08-08T18:30:49.142298Z",
     "iopub.status.idle": "2025-08-08T18:30:49.149154Z",
     "shell.execute_reply": "2025-08-08T18:30:49.148617Z"
    },
    "papermill": {
     "duration": 0.011027,
     "end_time": "2025-08-08T18:30:49.150240",
     "exception": false,
     "start_time": "2025-08-08T18:30:49.139213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # =========================================================================\n",
    "# # 1. IMPORTS\n",
    "# # =========================================================================\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.optim import AdamW\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "\n",
    "# # Suppress Hugging Face tokenizer parallelism warning\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# # =========================================================================\n",
    "# # 2. HYPERPARAMETER CONFIGURATION\n",
    "# # =========================================================================\n",
    "# class Config:\n",
    "#     # --- File Paths ---\n",
    "#     OFFLINE_MODEL_PATH = \"/kaggle/input/jigsaw-package/bert_base_uncased_offline/\"\n",
    "#     TRAIN_CSV_PATH = \"/kaggle/input/jigsaw-agile-community-rules/train.csv\"\n",
    "#     OUTPUT_DIR = \"./\"  # Directory to save models and plots\n",
    "\n",
    "#     # --- Model & Training Parameters ---\n",
    "#     MODEL_NAME = \"bert-base-uncased\"\n",
    "#     N_SPLITS = 5          # Number of folds for cross-validation\n",
    "#     EPOCHS = 3            # Number of epochs to train for each fold\n",
    "#     MAX_LEN = 128         # Max sequence length for tokenizer\n",
    "#     BATCH_SIZE = 16       # Batch size\n",
    "#     LR = 2e-5             # Learning Rate\n",
    "#     RANDOM_STATE = 42     # Random state for reproducibility\n",
    "\n",
    "# # Create output directory if it doesn't exist\n",
    "# if not os.path.exists(Config.OUTPUT_DIR):\n",
    "#     os.makedirs(Config.OUTPUT_DIR)\n",
    "\n",
    "# # =========================================================================\n",
    "# # 3. DATASET CLASS\n",
    "# # =========================================================================\n",
    "# class CommentDataset(Dataset):\n",
    "#     def __init__(self, texts, labels, tokenizer, max_len):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = str(self.texts[idx])\n",
    "#         label = self.labels[idx]\n",
    "        \n",
    "#         encoding = self.tokenizer(\n",
    "#             text,\n",
    "#             truncation=True,\n",
    "#             padding='max_length',\n",
    "#             max_length=self.max_len,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "        \n",
    "#         return {\n",
    "#             'input_ids': encoding['input_ids'].flatten(),\n",
    "#             'attention_mask': encoding['attention_mask'].flatten(),\n",
    "#             'labels': torch.tensor(label, dtype=torch.float)\n",
    "#         }\n",
    "\n",
    "# # =========================================================================\n",
    "# # 4. EVALUATION FUNCTION (Corrected)\n",
    "# # =========================================================================\n",
    "# def evaluate_model(model, dataloader, device, loss_fn):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     all_labels, all_preds = [], []\n",
    "#     all_probs = []  # <-- FIX 1: Initialize list to store all probabilities\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in dataloader:\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['labels'].to(device).unsqueeze(1)\n",
    "\n",
    "#             outputs = model(input_ids, attention_mask=attention_mask)\n",
    "#             loss = loss_fn(outputs.logits, labels)\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#             # Get probabilities and predictions for the current batch\n",
    "#             probs = torch.sigmoid(outputs.logits).cpu().numpy().flatten()\n",
    "#             preds = (probs >= 0.5).astype(int)\n",
    "            \n",
    "#             all_probs.extend(probs) # <-- FIX 2: Accumulate probabilities from each batch\n",
    "#             all_preds.extend(preds)\n",
    "#             all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "#     accuracy = accuracy_score(all_labels, all_preds)\n",
    "#     f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    \n",
    "#     # <-- FIX 3: Use the accumulated probabilities (all_probs) for AUC calculation\n",
    "#     auc = roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.5\n",
    "\n",
    "#     return avg_loss, accuracy, f1, auc\n",
    "\n",
    "\n",
    "# # =========================================================================\n",
    "# # 5. MAIN TRAINING SCRIPT\n",
    "# # =========================================================================\n",
    "# # --- Load Data ---\n",
    "# train_df = pd.read_csv(Config.TRAIN_CSV_PATH)\n",
    "# train_df['text'] = train_df['body'] + \" [RULE] \" + train_df['rule']\n",
    "\n",
    "# # --- Load Tokenizer ---\n",
    "# tokenizer = BertTokenizer.from_pretrained(Config.OFFLINE_MODEL_PATH)\n",
    "\n",
    "# # --- Initialize K-Fold ---\n",
    "# skf = StratifiedKFold(n_splits=Config.N_SPLITS, shuffle=True, random_state=Config.RANDOM_STATE)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# # --- Start Cross-Validation Loop ---\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['rule_violation'])):\n",
    "#     print(f\"\\n{'='*20} FOLD {fold+1} / {Config.N_SPLITS} {'='*20}\")\n",
    "\n",
    "#     # --- Prepare Data for current fold ---\n",
    "#     train_fold_df = train_df.iloc[train_idx]\n",
    "#     val_fold_df = train_df.iloc[val_idx]\n",
    "\n",
    "#     train_dataset = CommentDataset(\n",
    "#         texts=train_fold_df['text'].values,\n",
    "#         labels=train_fold_df['rule_violation'].values,\n",
    "#         tokenizer=tokenizer,\n",
    "#         max_len=Config.MAX_LEN\n",
    "#     )\n",
    "#     val_dataset = CommentDataset(\n",
    "#         texts=val_fold_df['text'].values,\n",
    "#         labels=val_fold_df['rule_violation'].values,\n",
    "#         tokenizer=tokenizer,\n",
    "#         max_len=Config.MAX_LEN\n",
    "#     )\n",
    "\n",
    "#     # Use a separate loader for evaluating on training data without shuffling\n",
    "#     train_eval_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "#     # --- Initialize Model, Optimizer, Loss for current fold ---\n",
    "#     model = BertForSequenceClassification.from_pretrained(Config.OFFLINE_MODEL_PATH, num_labels=1)\n",
    "#     model.to(device)\n",
    "\n",
    "#     optimizer = AdamW(model.parameters(), lr=Config.LR)\n",
    "#     total_steps = len(train_loader) * Config.EPOCHS\n",
    "#     scheduler = get_linear_schedule_with_warmup(\n",
    "#         optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    "#     )\n",
    "#     loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "#     # --- History Tracking for Plots ---\n",
    "#     history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "#     # --- Epoch Loop for current fold ---\n",
    "#     for epoch in range(Config.EPOCHS):\n",
    "#         print(f\"\\n--- Epoch {epoch+1}/{Config.EPOCHS} ---\")\n",
    "        \n",
    "#         # --- Training Phase ---\n",
    "#         model.train()\n",
    "#         epoch_train_loss = 0\n",
    "#         for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "#             optimizer.zero_grad()\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['labels'].to(device).unsqueeze(1)\n",
    "\n",
    "#             outputs = model(input_ids, attention_mask=attention_mask)\n",
    "#             loss = loss_fn(outputs.logits, labels)\n",
    "            \n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             scheduler.step()\n",
    "#             epoch_train_loss += loss.item()\n",
    "        \n",
    "#         avg_epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "#         history['train_loss'].append(avg_epoch_train_loss)\n",
    "\n",
    "#         # --- Evaluation Phase ---\n",
    "#         print(\"Evaluating...\")\n",
    "#         # Evaluate on Training Data\n",
    "#         _, train_acc, train_f1, train_auc = evaluate_model(model, train_eval_loader, device, loss_fn)\n",
    "#         # Evaluate on Validation Data\n",
    "#         val_loss, val_acc, val_f1, val_auc = evaluate_model(model, val_loader, device, loss_fn)\n",
    "#         history['val_loss'].append(val_loss)\n",
    "\n",
    "#         # Print Epoch Results\n",
    "#         print(f\"Epoch {epoch+1} Summary:\")\n",
    "#         print(f\"  Train Loss: {avg_epoch_train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "#         print(f\"  Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f} | Train AUC: {train_auc:.4f}\")\n",
    "#         print(f\"  Val Acc:   {val_acc:.4f} | Val F1:   {val_f1:.4f} | Val AUC:   {val_auc:.4f}\")\n",
    "\n",
    "#     # --- Save the model for the current fold ---\n",
    "#     model_path = os.path.join(Config.OUTPUT_DIR, f\"bert_fold_{fold}.pth\")\n",
    "#     torch.save(model.state_dict(), model_path)\n",
    "#     print(f\"\\nModel for Fold {fold+1} saved to {model_path}\")\n",
    "\n",
    "#     # --- Plot Training & Validation Loss for the current fold ---\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(history['train_loss'], label='Train Loss')\n",
    "#     plt.plot(history['val_loss'], label='Validation Loss')\n",
    "#     plt.title(f'Loss vs. Epochs for Fold {fold+1}')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "# print(\"\\nK-Fold Training Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e6e956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T18:30:49.154435Z",
     "iopub.status.busy": "2025-08-08T18:30:49.154250Z",
     "iopub.status.idle": "2025-08-08T18:31:42.027017Z",
     "shell.execute_reply": "2025-08-08T18:31:42.025952Z"
    },
    "papermill": {
     "duration": 52.876221,
     "end_time": "2025-08-08T18:31:42.028154",
     "exception": false,
     "start_time": "2025-08-08T18:30:49.151933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 18:31:06.060605: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754677866.244489      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754677866.298485      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n",
      "Paths and parameters defined.\n",
      "Dataset class defined.\n",
      "Tokenizer loaded and test data prepared.\n",
      "Using device: cuda\n",
      "\n",
      "--- Predicting with Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Fold 1: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predicting with Fold 2/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Fold 2: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predicting with Fold 3/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Fold 3: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predicting with Fold 4/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Fold 4: 100%|██████████| 1/1 [00:00<00:00, 18.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predicting with Fold 5/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Fold 5: 100%|██████████| 1/1 [00:00<00:00, 19.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble inference finished.\n",
      "\n",
      "Submission file 'submission.csv' created successfully!\n",
      "This file contains the averaged predictions from all model folds.\n",
      "Top 5 rows of the submission file:\n",
      "   row_id  rule_violation\n",
      "0    2029        0.214198\n",
      "1    2030        0.576999\n",
      "2    2031        0.630129\n",
      "3    2032        0.906403\n",
      "4    2033        0.931362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# 1. IMPORTS\n",
    "# =========================================================================\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "\n",
    "# =========================================================================\n",
    "# 2. DEFINE PATHS AND PARAMETERS\n",
    "# =========================================================================\n",
    "class Config:\n",
    "    # --- File Paths ---\n",
    "    OFFLINE_MODEL_PATH = \"/kaggle/input/jigsaw-package/bert_base_uncased_offline/\"\n",
    "    TEST_CSV_PATH = \"/kaggle/input/jigsaw-agile-community-rules/test.csv\"\n",
    "    \n",
    "    # --- IMPORTANT: Path to the directory where your k-fold models are saved ---\n",
    "    MODEL_DIR = \"/kaggle/input/jigsaw-model/\" \n",
    "\n",
    "    # --- Model & Dataloader Parameters ---\n",
    "    N_SPLITS = 5          # Should match the number of folds used during training\n",
    "    MAX_LEN = 128         # Should match the max_len used during training\n",
    "    BATCH_SIZE = 16       # Can be adjusted for inference speed/memory\n",
    "\n",
    "print(\"Paths and parameters defined.\")\n",
    "\n",
    "# =========================================================================\n",
    "# 3. DATASET CLASS (Unchanged)\n",
    "# =========================================================================\n",
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in enc.items()}\n",
    "        return item\n",
    "\n",
    "print(\"Dataset class defined.\")\n",
    "\n",
    "# =========================================================================\n",
    "# 4. LOAD TOKENIZER AND PREPARE TEST DATA (Unchanged)\n",
    "# =========================================================================\n",
    "tokenizer = BertTokenizer.from_pretrained(Config.OFFLINE_MODEL_PATH)\n",
    "test_df = pd.read_csv(Config.TEST_CSV_PATH)\n",
    "\n",
    "# Preprocess the test data\n",
    "test_df['text'] = test_df['body'] + \" [RULE] \" + test_df['rule']\n",
    "test_texts = test_df['text'].tolist()\n",
    "\n",
    "test_dataset = CommentDataset(texts=test_texts, tokenizer=tokenizer, max_len=Config.MAX_LEN)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Tokenizer loaded and test data prepared.\")\n",
    "\n",
    "# =========================================================================\n",
    "# 5. LOAD MODELS AND RUN ENSEMBLE INFERENCE\n",
    "# =========================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Get paths to all saved model folds\n",
    "model_paths = [os.path.join(Config.MODEL_DIR, f\"bert_fold_{i}.pth\") for i in range(Config.N_SPLITS)]\n",
    "all_fold_probs = []\n",
    "\n",
    "# --- Loop through each model fold for inference ---\n",
    "for fold, path in enumerate(model_paths):\n",
    "    print(f\"\\n--- Predicting with Fold {fold+1}/{Config.N_SPLITS} ---\")\n",
    "    \n",
    "    # Load the base model structure\n",
    "    model = BertForSequenceClassification.from_pretrained(Config.OFFLINE_MODEL_PATH, num_labels=1)\n",
    "    \n",
    "    # Load the fine-tuned weights for the current fold\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Model file not found at {path}. Make sure the MODEL_DIR is correct.\")\n",
    "        print(\"Skipping this fold.\")\n",
    "        continue # Skip to the next fold if a model file is missing\n",
    "        \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Store probabilities for the current fold\n",
    "    current_fold_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Predicting Fold {fold+1}\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.sigmoid(outputs.logits).cpu().numpy().flatten()\n",
    "            current_fold_probs.extend(probs)\n",
    "    \n",
    "    all_fold_probs.append(current_fold_probs)\n",
    "\n",
    "print(\"\\nEnsemble inference finished.\")\n",
    "\n",
    "# =========================================================================\n",
    "# 6. AVERAGE PREDICTIONS AND CREATE SUBMISSION FILE\n",
    "# =========================================================================\n",
    "if not all_fold_probs:\n",
    "    print(\"Could not generate predictions as no model files were found. Exiting.\")\n",
    "else:\n",
    "    # Convert the list of fold predictions into a numpy array\n",
    "    predictions_array = np.array(all_fold_probs)\n",
    "\n",
    "    # Average the predictions across all folds (axis=0)\n",
    "    final_probs = np.mean(predictions_array, axis=0)\n",
    "\n",
    "    # Create the submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'row_id': test_df['row_id'],\n",
    "        'rule_violation': final_probs\n",
    "    })\n",
    "\n",
    "    # Save the final submission file\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "    print(\"\\nSubmission file 'submission.csv' created successfully!\")\n",
    "    print(\"This file contains the averaged predictions from all model folds.\")\n",
    "    print(\"Top 5 rows of the submission file:\")\n",
    "    print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13121456,
     "isSourceIdPinned": false,
     "sourceId": 94635,
     "sourceType": "competition"
    },
    {
     "datasetId": 8031965,
     "sourceId": 12708542,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8032272,
     "isSourceIdPinned": true,
     "sourceId": 12712610,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 262.354596,
   "end_time": "2025-08-08T18:31:44.859550",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-08T18:27:22.504954",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
